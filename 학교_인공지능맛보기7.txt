ㅁCNN
ㅇ이론
-기존에 라이브러리로 써왔던 머신 러닝 방식에서 이미지 학습 방식은 그냥 픽셀 하나하나를 보는 것에 불과하다.

-어떤 한 픽셀이 빨간 색 픽셀이라면 다른 인접한 픽셀은 어지간하면 빨간 색일 확률이 굉장히 높다는 점에 착안하여,

-CNN은 이미지 특징을 같이 알려주는 방법이다. (주성분 분석과는 다른 방법이다.)
특징 ex ) (사진개수)x(가로픽셀)x(세로픽셀)x(흑백: 1 / 컬러: 3 )

-이미지의 특징을 잡는 방법은 컨볼루션 레이어라는 것을 활용하는 것이다.
same padding과 valid padding으로 컨볼루션 레이어의 활용방법이 나뉜다.

same padding : 특징점을 잡은 결과값의 크기와 원본 이미지의 크기가 같아짐.(원본 이미지 주변을 값이 0인 픽셀로 둘러싼다. 모든 곳을 좀 더 골고루 특징점을 잡을 때 사용)
valid padding : 특징점을 잡은 결과값이 크기가 원본 이미지 크기보다는 작다. (원본 이미지 주변을 값이 0인 픽셀로 둘러싸지 않음)

그리고 CNN은 특징점을 한 번만 잡고 끝내지 않고, 한 과정에 여러 개의 특징점 집합을 생성한다. (그래서 꽤 오래 걸림) 
즉, 사진 1장이 있다면 한 번 컨볼루션(특징점 잡기)를 거치면 CNN을 통해 32장이 되고, 또 한 번 그 사진으로 컨볼루션을 하면 CNN을 통해 64장이 되고... 그런 식이다.

(대략적인 느낌은 무엇이냐면,
마스크 하나를 준비해서, 마스크 하나의 크기로 자른 이미지에서 특징을 잡아낸다는 것이다.
5x5짜리 이미지를 3x3만큼 여러 번 자르고, 각각의 잘려진 3x3 이미지에서 특징을 잡아 한 픽셀로 만든다.
그렇게 해서 3x3 특징점 사진을 만들어 낸다. 영상 ppt 참고.)

-텐서플로우 CNN 기준 4차원의 배열로 학습 데이터를 넣어줘야한다.
(사진개수)x(가로픽셀)x(세로픽셀)x(흑백: 1 / 컬러: 3 )

-풀링

맥스풀링 : 각각 특징점을 잡는 이미지 마스크에서 가장 큰 값을 가진 픽셀만 가지고 온다. 그래서 확실하게 이미지 크기가 감소한다.
(ex 4x4 사진을 2x2로 줄인다.)
=>주성분 분석과는 달리 원본 이미지보다 더 성능이 개선되는 경우가 생긴다. (주성분 분석에서는 성능의 개선은 기대할 수가 없다.)

ㅇ라이브러리 활용

tip) 인공신경망이나 딥러닝을 활용할 때, validation data를 활용할 때 시험데이터를 활용해서는 안된다.
그리고, 시험 데이터로 평가를 할 때는 1번만 평가해야한다. 시험 데이터로만 평가를 해서 모델을 계속 수정하면 결국 시험데이터에도 과대적합인 모델이 되기 때문이다.
그래서 검증 데이터 또한 따로 만들어서 검증 데이터의 결과를 기반으로 해서 모델을 수정한다. 그렇게 수정한 모델을 시험 데이터로 딱 한 번 평가를 해보면 충분하다.

-컨볼루션 레이어를 추가하는 코드는 다음과 같다.

model.add(keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(28,28,1)))

keras.layers.Conv2D(이미지갯수,kernel_size=(),activation=,padding=,input_shape=())
처음 인자는 한 이미지로 생성할 특징점 마스크 개수, kernel size는 마스크의 크기, activation은 활성화함수, padding은 same or valid, input shape는 (가로, 세로, 흑백/컬러)

-맥스풀링을 추가하는 코드는 다음과 같다.

model.add(keras.layers.MaxPooling2D(2)) 

keras.layers.MaxPooling2D(2)

인자는 이미지를 몇 배 크기로 압축할지 결정한다.

-은닉층에 이미지를 넣기 위해서는 이미지를 한 줄로 쭉 펴주어야 한다. ( 300x10000 이런 식으로)

그러기 위해서는...

model.add(keras.layers.Flatten()) 

이런 레이어를 추가해주면 된다.

-모델이 어떤 플로우를 가지는지 알아보려면...

keras.utils.plot_model(model,show_shapes=True)

이런 걸 쓰면 된다.

tip)
model.compile(loss='sparse_categorical_crossentropy',metrics='accuracy',optimizer='adam')
adam : 학습율을 자동으로 조절해준다. (학습율이 좋으면 방해를 줄이도록(?) << 확실치 않음, 학습율이 나쁘면 더 방해를 하도록 한다.)

-이것을 기반으로 한 이미지 학습 모델 (이미지 대회에서 입상한 모델)
ResNet, VGGNET, GoogleNet

ㅁRNN

-시계열에 관련됨.

-텍스트, 음성 데이터에 활용.

-학습 데이터가 A->B->C 순서로 들어왔다고 하자. 기존 방식에서는 A,B,C는 그냥 학습해야할 데이터일 뿐 컴퓨터는 A,B,C 간에 관계를 짓지는 않는다.
RNN에서는 A 데이터가 들어왔던 것을 기억하고 있다가 B 데이터가 들어왔을 때 B 데이터에 'A가 이전에 들어왔음'을 반영한다. 그리고 C 데이터가 들어오면 C 데이터에 'B가 이전에 들어왔음'을 반영한다
대략 이런 식으로 동작한다. (한 데이터가 기억하는 건 하나 이전의 데이터일 뿐이다.)

강사 왈 : A가 들어오면 기계는 A를 학습하고 A가 고리에 걸린다. B가 들어오면 기계는 B와 고리에 걸린 A도 보고 학습을 한다. 그리고 B가 A를 대체하여 고리에 걸린다. 
C가 들어오면 기계는 C와 고리에 걸린 B를 보고 학습을 한다. 그리고 C는 B를 대체하여 고리에 걸린다. (이전의 것만 알 수 있다.)

ㅇ라이브러리 활용

-무작위로 긁어온 텍스트 데이터의 경우, 텍스트 길이는 전부 다를 수가 있다.
근데 그러면 인공신경망에 집어넣을 수 없다. (크기는 전부 같아야하기 때문)

다음 라이브러리를 활용한다.
from tensorflow.keras.preprocessing.sequence import pad_sequences

그리고 이 함수를 활용한다.
train_seq=pad_sequences(train_input,maxlen=,truncating=)
단어의 갯수가 몇 개건 maxlen에 명시한 갯수만큼 자른다.
truncating은 maxlen을 넘어서는 경우 어디서부터 자를지 결정하는 것으로, pre면 앞에서부터, post면 뒤에서부터 자른다.

데이터셋으로 받아온 train_input을 보면 단어가 숫자로 표기되어있는데, 이 수치에 의해 중요도를 오인할 수도 있다. 그래서 이번엔 input에 원핫인코딩을 적용해줘야한다.
(원핫 인코딩을 할 경우 (25000,100,num_word) 이런 식으로 바뀌는데, 의미는 num_word개 열을 가진 1차원 배열이 100개 있는 2차원배열을 25000개 갖는단 의미다.)

RNN을 사용하는 방법은 다음과 같다.
model.add(keras.layers.SimpleRNN(다음 층의 노드개수,input_shape=(100,300)))
(원핫 인코딩 해준 형태를 input shape에 반영해줘야한다.)

RNN의 문제점은 데이터를 받아들일수록 초반부에 받아들인 데이터를 반영하여 학습할 수 없다는 점에 있다.

LSTM(long short term memory)는 A->B->C->D->E 데이터가 들어온다고 해보자.
A가 지나가면 A가 고리에 걸리고, 
B가 지나가면 기계는 A가 고리에 걸린 걸 보고 학습한다. 그리고 B도 고리에 걸린다.
C가 지나가면 기계는 A,B가 고리에 걸린 걸 보고 학습한다. 그리고 C도 고리에 걸린다.
D가 지나가면 기계는 A,B,C가 고리에 걸린 걸 보고 학습한다. 그리고 D도 고리에 걸린다.
E가 지나가면 기계는 A,B,C,D가 고리에 걸린 걸 보고 학습한다. 그리고 A는 빠지고 E가 대체하여 고리에 걸린다.
대충 이런 식이다. RNN과 비슷하지만, 고리에 좀 더 많이 걸어두어 초반부 데이터를 학습할 수 있도록 한다.

LSTM의 사용방법은 다음과 같다.
model.add(keras.layers.LSTM(8,input_shape=(100,300)))

그리고 LSTM은 겹겹이 층을 쌓는 것은 일반적인 방법으로는 불가능하다.
( ㅁ - ㅁ 이런 식으로 하는 것을 불가능하다는 말이다.)

구조를 보자면 | ㅁㅁ | 이런 식으로 겹치는 것이다. (융합?에 가깝다)

겹치려면 다음과 같이 한다.
model.add(keras.layers.LSTM(8,input_shape=(100,200),return_sequences=True))
model.add(keras.layers.LSTM(...))

return_sequences : 아웃풋 시퀀스의 마지막 아웃풋을 반환할지, 혹은 시퀀스 전체를 반환할지 여부
(false면 시퀀스 마지막 아웃풋을, true면 시퀀스 자체를 반환한다. 그림(?) 참조) 

LSTM 내부(?)에서도 dropout을 적용할 수 있다. 다음과 같이 쓴다.
model.add(keras.layers.LSTM(8,dropout=...))
이 때 적어줘야할 것은 0~1 사이의 소수다.